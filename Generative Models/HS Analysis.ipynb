{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# from rpy2.robjects import pandas2ri\n",
    "# pandas2ri.activate()\n",
    "\n",
    "#Functions for reading two different .csv files\n",
    "def read_hs1(yoozer):\n",
    "    pd_df = pd.read_csv('../../Data/suggest-analysis-kristjan.csv') #'suggest-analysis-kristjan.csv')\n",
    "    pdf = pd_df[:179]\n",
    "    snda = pd_df['send.active'] == 1\n",
    "    snd = pd_df['send'] == 0\n",
    "    usr = pd_df['user'] == yoozer\n",
    "    ddf = pd_df[(snda | snd) & usr]\n",
    "    ddf = ddf.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    return ddf,pd_df\n",
    "\n",
    "def read_hs1_gf(yoozer):\n",
    "    pd_df = pd.read_csv('../../Data/suggest-kristjan.csv') #'suggest-analysis-kristjan.csv')\n",
    "    pdf = pd_df[:179]\n",
    "    snda = pd_df['send.active'] == 1\n",
    "    snd = pd_df['send'] == 0\n",
    "    usr = pd_df['user'] == yoozer\n",
    "    ddf = pd_df[(snda | snd) & usr]\n",
    "    ddf = ddf.reset_index(drop=True)\n",
    "\n",
    "    return ddf,pd_df\n",
    "\n",
    "\n",
    "def nan_equal(a,b):\n",
    "    return ((a == b) | (np.isnan(a) & np.isnan(b))).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Counts from HS 1\n",
    "\n",
    "N = 48\n",
    "T = 41\n",
    "t = 5\n",
    "num_feats = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda2\\envs\\cs281\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2802: DtypeWarning: Columns (15,16,18,60,61,96,97,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "max_yoozer = N+1\n",
    "\n",
    "featVec = np.empty((max_yoozer,T*t, num_feats))\n",
    "featVec.fill(np.nan)\n",
    "\n",
    "rewardVec = np.empty((max_yoozer,T*t))\n",
    "rewardVec.fill(np.nan)\n",
    "\n",
    "actionVec = np.empty((max_yoozer,T*t))\n",
    "actionVec.fill(np.nan)\n",
    "\n",
    "# Bias term\n",
    "\n",
    "for yoozer in range(1,max_yoozer):\n",
    "    # Edit to be actual list of users\n",
    "    print(yoozer)\n",
    "\n",
    "    ddf,pd_df = read_hs1(yoozer)\n",
    "    #Make features\n",
    "    #Center and scale\n",
    "    decision_ind = ddf['decision.index.nogap']\n",
    "    state = (ddf['jbsteps30pre.log'] - np.mean(pd_df['jbsteps30pre.log']))/np.std(pd_df['jbsteps30pre.log'])\n",
    "    reward_h = ddf['jbsteps30.log']\n",
    "    send_any = ddf['send']\n",
    "    send_active = ddf['send.active']\n",
    "    \n",
    "    assert np.all(send_any == send_active)\n",
    "    \n",
    "    #total_sent = ddf['totalSent']\n",
    "    # Study day index\n",
    "    dazze = ddf['study.day.nogap']\n",
    "\n",
    "    day_ind  = (ddf['study.day.nogap'] - np.mean(pd_df['study.day.nogap']))/np.std(pd_df['study.day.nogap'])#Number sent in last whatever\n",
    "    #Add feature for # of week period (hsteps v2) WATCH OUT FOR COLINEARITY WITH INTERCEPT\n",
    "    # Work indicator\n",
    "    #wrk_ind = ddf['location.category']\n",
    "    wrk_ind = ddf['loc.is.work'] #compare to string “work”\n",
    "    # Location indicator\n",
    "    loc_ind = ddf['loc.is.other']\n",
    "    #loc_ind = ddf['location.category']\n",
    "    steps_yest = (ddf['steps.yesterday.sqrt'] - np.mean(pd_df['steps.yesterday.sqrt']))/np.std(pd_df['steps.yesterday.sqrt'])\n",
    "\n",
    "    steps_sd = (ddf['window7.steps60.sd'] - np.mean(pd_df['window7.steps60.sd']))/np.std(pd_df['window7.steps60.sd'])\n",
    "    temp = (ddf['temperature'] - np.mean(pd_df['temperature']))/np.std(pd_df['temperature'])\n",
    "    temp[ddf['temperature'] == -1024] = 0\n",
    "\n",
    "    ddfgf,pd_dfgf = read_hs1_gf(yoozer)\n",
    "\n",
    "    steps_gf = (np.log(ddfgf['gfsteps30pre'] + .5) - np.mean(np.log(pd_dfgf['gfsteps30pre'] + .5))/np.std(np.log(pd_dfgf['gfsteps30pre']+.5)))\n",
    "\n",
    "    end_ind = day_ind.shape[0]\n",
    "\n",
    "    \n",
    "    # Set reward, action, and state\n",
    "    rewardVec[yoozer,:end_ind] = reward_h.astype(float)\n",
    "    actionVec[yoozer,:end_ind] = send_any.astype(float)\n",
    "    \n",
    "    featVec[yoozer,:end_ind,0].fill(1) # Only fill rows with observations\n",
    "    featVec[yoozer,:end_ind,1] = day_ind\n",
    "    featVec[yoozer,:end_ind,2] = loc_ind.astype(int)\n",
    "    featVec[yoozer,:end_ind,3] = steps_sd.astype(float)\n",
    "    featVec[yoozer,:end_ind,4] = state\n",
    "    featVec[yoozer,:end_ind,5] = wrk_ind.astype(int)\n",
    "    featVec[yoozer,:end_ind,6] = steps_yest\n",
    "    featVec[yoozer,:end_ind,7] = temp.astype(float)\n",
    "    featVec[yoozer,:end_ind,8] = steps_gf.astype(float)[:day_ind.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TREAT DATA ##\n",
    "\n",
    "# Drop 0th user, since users are 1-indexed\n",
    "featVec = featVec[1:,:,:].copy()\n",
    "rewardVec = rewardVec[1:,:].copy()\n",
    "actionVec = actionVec[1:,:].copy()\n",
    "\n",
    "# Reshape actionVec to have additional 1 dim\n",
    "actionVec = actionVec.reshape(actionVec.shape[0],actionVec.shape[1],1)\n",
    "\n",
    "# Mean impute featVec where there is an observation\n",
    "featVec[~np.isnan(featVec[:,:,1])] = np.nan_to_num(featVec[~np.isnan(featVec[:,:,1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Actual Dimensions\n",
    "A_dim = 1\n",
    "S_dim = num_feats\n",
    "\n",
    "# Copy for notational ease\n",
    "R = rewardVec.copy()\n",
    "A = actionVec.copy()\n",
    "S = featVec.copy()\n",
    "\n",
    "\n",
    "# Fit OLS r ~ (a,s)^T \\theta\n",
    "model = sm.OLS(endog = R.reshape(N*T*t), exog = np.concatenate([A,S],2).reshape((N*T*t,(A_dim + S_dim))), missing=\"drop\")\n",
    "resids = model.fit().resid\n",
    "\n",
    "\n",
    "## Fill Eta ##\n",
    "\n",
    "# Copy shape and location of nans\n",
    "Eta = rewardVec.copy()\n",
    "\n",
    "curr_ind = 0\n",
    "for n in range(N):\n",
    "    \n",
    "    old_ind = curr_ind\n",
    "    curr_ind += R[n][~np.isnan(R[n])].shape[0]\n",
    "    \n",
    "    # Copy in indices\n",
    "    Eta[n][:curr_ind-old_ind] = resids[old_ind:curr_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_new_users(Eta, A, S, N_new, T_new, T, t, users_to_sample = 10):\n",
    "    '''\n",
    "    Generates new random user\n",
    "    \n",
    "    \n",
    "    Inputs:\n",
    "        Eta: Residuals\n",
    "        A: Actions\n",
    "        S: States\n",
    "        N_new: Int of number of new users to generate from sampling\n",
    "        T_new: Int of number of days for each new user\n",
    "    \n",
    "    Returns:\n",
    "        Eta_new: Matrix of Etas for sampled users\n",
    "        A_new: Matrix of associated actions for sampled users\n",
    "        S_new: Matrix of associated states for sampled users\n",
    "        \n",
    "    *Assumes shapes:\n",
    "      Eta: (N, T * t) \n",
    "      A: (N, T * t, )\n",
    "    '''\n",
    "    \n",
    "    # Obtain original dimensions of data from actions A\n",
    "    N = A.shape[0]\n",
    "\n",
    "    # Component dims of A and S \n",
    "    a_dim = A.shape[2]\n",
    "    s_dim = S.shape[2]\n",
    "\n",
    "    # Sample random users from original data\n",
    "    sampled_user_indices = np.empty((N_new, users_to_sample)).astype(int)\n",
    "\n",
    "    # Loop to reset sampling without replacement for each new user\n",
    "    for i in range(N_new):\n",
    "        sampled_user_indices[i] = np.random.choice(N, size = users_to_sample, replace = False)\n",
    "    \n",
    "    # Concatenate Eta, A, and S to ensure processing is uniform\n",
    "    concat_data = np.concatenate([np.expand_dims(Eta,2),A,S], axis = 2)\n",
    "    sampled_users_untreated = np.take(concat_data, sampled_user_indices, 0).reshape(N_new, users_to_sample * T*t, 1 + a_dim + s_dim)\n",
    "    sampled_users = np.empty((N_new, T_new * t, 1 + a_dim + s_dim))\n",
    "    \n",
    "    for i in range(N_new):\n",
    "        \n",
    "        # Cast to DataFrame to dropna, reset index to shift datapoints up to be consecutive, takes T_new * t datapoints\n",
    "        sampled_users[i] = pd.DataFrame(sampled_users_untreated[i]).apply(lambda col: col.dropna().reset_index().iloc[:,-1], axis = 0).as_matrix()[:T_new * t]\n",
    "        \n",
    "    # Sampled Generated residuals\n",
    "    Eta_new = sampled_users[:,:,0].reshape(N_new, T_new, t)\n",
    "    # Sampled actions\n",
    "    A_new = sampled_users[:,:,1:(1+a_dim)].reshape(N_new, T_new, t, a_dim)\n",
    "    # Sampled states\n",
    "    S_new = sampled_users[:,:,(1+a_dim):].reshape(N_new, T_new, t, s_dim)\n",
    "\n",
    "    return Eta_new, A_new, S_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate new Users\n",
    "Eta_new, A_new, S_new = generate_new_users(Eta, A, S, 20, 90, T, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (20,90,5,10) and (12,) not aligned: 10 (dim 3) != 12 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-a1922f43ff49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mEta\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEta_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-87-a1922f43ff49>\u001b[0m in \u001b[0;36mreward_func\u001b[1;34m(Eta, A, S, Theta)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mreward_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;34m'''Basic reward function, can edit for different generative models'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mEta\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEta_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (20,90,5,10) and (12,) not aligned: 10 (dim 3) != 12 (dim 0)"
     ]
    }
   ],
   "source": [
    "def reward_func(Eta, A, S, Theta):\n",
    "    '''Basic reward function, can edit for different generative models'''\n",
    "    return Eta + np.concatenate([A, S], A.ndim-1).dot(Theta)\n",
    "\n",
    "# print(reward_func(Eta_new, A_new, S_new, np.array(range(12))))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cs281]",
   "language": "python",
   "name": "conda-env-cs281-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
